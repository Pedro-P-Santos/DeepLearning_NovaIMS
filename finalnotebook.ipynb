{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Rescaling\n",
    "\n",
    "# model building imports\n",
    "from keras import Model, Sequential, Input\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.ops import add\n",
    "from keras.utils import to_categorical\n",
    "# model training imports\n",
    "from keras.optimizers import SGD\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.metrics import CategoricalAccuracy, AUC, F1Score\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "\n",
    "\n",
    "from keras.layers import RandomContrast, RandomSharpness\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
    "from tensorflow.keras.layers import RandAugment\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "from library import vis_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Import version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Caminho base onde estão as pastas com imagens\n",
    "# base_image_dir = 'C:/Users/luisp/OneDrive/Mestrado/1ano/2sem/Deep Learning (DL)/Project/rare_species 1'\n",
    "\n",
    "# # Criar coluna com caminho absoluto para cada imagem\n",
    "# metadata['absolute_path'] = metadata['file_path'].apply(lambda x: os.path.join(base_image_dir, x))\n",
    "\n",
    "# # Verificar se o ficheiro existe no disco\n",
    "# metadata['exists_on_disk'] = metadata['absolute_path'].apply(os.path.exists)\n",
    "\n",
    "# # Mostrar quantos existem e quantos faltam\n",
    "# total_in_metadata = len(metadata)\n",
    "# existing_on_disk = metadata['exists_on_disk'].sum()\n",
    "# real_images_on_disk = sum(len(files) for _, _, files in os.walk(base_image_dir))\n",
    "\n",
    "# print(f\"Total de imagens no metadata: {total_in_metadata}\")\n",
    "# print(f\"Total de imagens que existem no disco: {existing_on_disk}\")\n",
    "# print(f\"Total real de ficheiros de imagem no disco: {real_images_on_disk}\")\n",
    "\n",
    "# # Mostrar exemplos de imagens em falta\n",
    "# print(\"\\nExemplos de imagens em falta:\")\n",
    "# print(metadata[~metadata['exists_on_disk']][['file_path']].head())\n",
    "\n",
    "# # Remover entradas com ficheiros em falta\n",
    "# metadata_clean = metadata[metadata['exists_on_disk']].drop(columns=['exists_on_disk'])\n",
    "\n",
    "# # Guardar novo ficheiro limpo\n",
    "# metadata_clean.to_csv(\"C:/Users/luisp/OneDrive/Mestrado/1ano/2sem/Deep Learning (DL)/Project/rare_species 1/metadata_clean.csv\", index=False)\n",
    "\n",
    "# print(\"\\n✅ metadata_clean.csv guardado com sucesso — apenas com imagens existentes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Import 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is comented because this split was already done in our pcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path=r\"C:\\Users\\User\\Desktop\\deeplearning\\metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rare_species_id</th>\n",
       "      <th>eol_content_id</th>\n",
       "      <th>eol_page_id</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>phylum</th>\n",
       "      <th>family</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75fd91cb-2881-41cd-88e6-de451e8b60e2</td>\n",
       "      <td>12853737</td>\n",
       "      <td>449393</td>\n",
       "      <td>animalia</td>\n",
       "      <td>mollusca</td>\n",
       "      <td>unionidae</td>\n",
       "      <td>mollusca_unionidae/12853737_449393_eol-full-si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28c508bc-63ff-4e60-9c8f-1934367e1528</td>\n",
       "      <td>20969394</td>\n",
       "      <td>793083</td>\n",
       "      <td>animalia</td>\n",
       "      <td>chordata</td>\n",
       "      <td>geoemydidae</td>\n",
       "      <td>chordata_geoemydidae/20969394_793083_eol-full-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00372441-588c-4af8-9665-29bee20822c0</td>\n",
       "      <td>28895411</td>\n",
       "      <td>319982</td>\n",
       "      <td>animalia</td>\n",
       "      <td>chordata</td>\n",
       "      <td>cryptobranchidae</td>\n",
       "      <td>chordata_cryptobranchidae/28895411_319982_eol-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29cc6040-6af2-49ee-86ec-ab7d89793828</td>\n",
       "      <td>29658536</td>\n",
       "      <td>45510188</td>\n",
       "      <td>animalia</td>\n",
       "      <td>chordata</td>\n",
       "      <td>turdidae</td>\n",
       "      <td>chordata_turdidae/29658536_45510188_eol-full-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94004bff-3a33-4758-8125-bf72e6e57eab</td>\n",
       "      <td>21252576</td>\n",
       "      <td>7250886</td>\n",
       "      <td>animalia</td>\n",
       "      <td>chordata</td>\n",
       "      <td>indriidae</td>\n",
       "      <td>chordata_indriidae/21252576_7250886_eol-full-s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        rare_species_id  eol_content_id  eol_page_id  \\\n",
       "0  75fd91cb-2881-41cd-88e6-de451e8b60e2        12853737       449393   \n",
       "1  28c508bc-63ff-4e60-9c8f-1934367e1528        20969394       793083   \n",
       "2  00372441-588c-4af8-9665-29bee20822c0        28895411       319982   \n",
       "3  29cc6040-6af2-49ee-86ec-ab7d89793828        29658536     45510188   \n",
       "4  94004bff-3a33-4758-8125-bf72e6e57eab        21252576      7250886   \n",
       "\n",
       "    kingdom    phylum            family  \\\n",
       "0  animalia  mollusca         unionidae   \n",
       "1  animalia  chordata       geoemydidae   \n",
       "2  animalia  chordata  cryptobranchidae   \n",
       "3  animalia  chordata          turdidae   \n",
       "4  animalia  chordata         indriidae   \n",
       "\n",
       "                                           file_path  \n",
       "0  mollusca_unionidae/12853737_449393_eol-full-si...  \n",
       "1  chordata_geoemydidae/20969394_793083_eol-full-...  \n",
       "2  chordata_cryptobranchidae/28895411_319982_eol-...  \n",
       "3  chordata_turdidae/29658536_45510188_eol-full-s...  \n",
       "4  chordata_indriidae/21252576_7250886_eol-full-s...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11983, 7)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata['family'] = metadata['family'].astype(str)  # Ensure it's a string\n",
    "# metadata['file_path'] = metadata['file_path'].astype(str)  # Ensure path is string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define output directories\n",
    "# output_base = r\"/Users/pedrosantos/Documents 2/Deep Learning/Projeto/rare_species 1/dataset_split\"\n",
    "# os.makedirs(output_base, exist_ok=True)\n",
    "# for split in ['train', 'val', 'test']:\n",
    "#     os.makedirs(os.path.join(output_base, split), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stratified split at image level\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_files, temp_files = train_test_split(metadata, test_size=0.3, stratify=metadata['family'], random_state=42)\n",
    "# val_files, test_files = train_test_split(temp_files, test_size=0.5, stratify=temp_files['family'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def move_files(file_subset, split_name):\n",
    "#     for _, row in file_subset.iterrows():\n",
    "#         src_path = os.path.join(dataset_directory, row['file_path'])  # Construct full path\n",
    "#         dst_path = os.path.join(output_base, split_name, row['file_path'])\n",
    "#         os.makedirs(os.path.dirname(dst_path), exist_ok=True)  # Ensure folder structure\n",
    "#         if os.path.exists(src_path):\n",
    "#             shutil.copy2(src_path, dst_path)\n",
    "#         else:\n",
    "#             print(f\"Warning: {src_path} not found.\")\n",
    "\n",
    "# # Move images to respective folders\n",
    "# move_files(train_files, 'train')\n",
    "# move_files(val_files, 'val')\n",
    "# move_files(test_files, 'test')\n",
    "\n",
    "# print(\"Dataset split completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"/Users/pedrosantos/Documents 2/Deep Learning/Projeto/rare_species 1/dataset_split/train\"\n",
    "valid_path = r\"/Users/pedrosantos/Documents 2/Deep Learning/Projeto/rare_species 1/dataset_split/val\"\n",
    "test_path = r\"/Users/pedrosantos/Documents 2/Deep Learning/Projeto/rare_species 1/dataset_split/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"C:\\Users\\User\\Desktop\\deeplearning\\dataset_split\\train\"\n",
    "valid_path = r\"C:\\Users\\User\\Desktop\\deeplearning\\dataset_split\\val\"\n",
    "test_path = r\"C:\\Users\\User\\Desktop\\deeplearning\\dataset_split\\test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8388 files belonging to 202 classes.\n",
      "Found 1797 files belonging to 202 classes.\n",
      "Found 1798 files belonging to 202 classes.\n"
     ]
    }
   ],
   "source": [
    "train = keras.utils.image_dataset_from_directory(\n",
    "    directory = train_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=32,\n",
    "    image_size=(224,224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    interpolation = \"bilinear\"\n",
    ")\n",
    "\n",
    "validation = keras.utils.image_dataset_from_directory(\n",
    "    directory = valid_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=32,\n",
    "    image_size=(224,224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    interpolation = \"bilinear\"\n",
    ")\n",
    "\n",
    "test = keras.utils.image_dataset_from_directory(\n",
    "    directory = test_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=32,\n",
    "    image_size=(224,224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    interpolation = \"bilinear\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mvis_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\DeepLearning_NovaIMS\\library.py:2\u001b[39m, in \u001b[36mvis_images\u001b[39m\u001b[34m(train)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvis_images\u001b[39m(train):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mplt\u001b[49m.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m10\u001b[39m))\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train.take(\u001b[32m1\u001b[39m):\n\u001b[32m      4\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m9\u001b[39m):\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "vis_images(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
